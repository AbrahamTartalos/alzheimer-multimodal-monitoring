{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63d2c79-2599-4a77-b1d0-c8b6d3423b7b",
   "metadata": {},
   "source": [
    "# 09d - Temporal Analysis Models\n",
    " \n",
    "**Objetivo**: Desarrollar modelos de an√°lisis temporal para entender la evoluci√≥n del riesgo de Alzheimer a lo largo del tiempo\n",
    " \n",
    "**Componentes principales**:\n",
    "- An√°lisis de tendencias temporales en biomarcadores\n",
    "- Modelos de series de tiempo para predicci√≥n de progresi√≥n\n",
    "- An√°lisis de patrones temporales en actividad/sue√±o\n",
    "- Detecci√≥n de cambios significativos en el tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d262215-a3b0-4869-99f6-39fd7a8c357e",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8239179-2859-4bbe-a07d-3980d8e18326",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d2c002-a65d-4b3a-a591-4d8837a6b23a",
   "metadata": {},
   "source": [
    "## Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68cd4dd-c990-4b1b-8001-5df357e0c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../scripts/modeling')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importar m√≥dulos personalizados\n",
    "from temporal_modeling import TemporalAnalyzer, TimeSeriesPredictor\n",
    "from model_utils import ModelTracker\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23342975-7b35-4681-8910-9fe585eddd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
    "print(f\"üìÖ Fecha de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24fee8-fb00-4364-ac58-c0d3e469e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n MLflow\n",
    "mlflow.set_experiment(\"alzheimer_temporal_analysis\")\n",
    "\n",
    "# Inicializar tracker\n",
    "tracker = ModelTracker(experiment_name=\"alzheimer_temporal_analysis\")\n",
    "\n",
    "print(\"üîß MLflow configurado para An√°lisis Temporal\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393b1068-c410-4ef7-9803-203c0109384f",
   "metadata": {},
   "source": [
    "## Carga y Preparaci√≥n de Datos Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b2fe01-fc38-4da6-a53e-2bb87b7cfe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos procesados\n",
    "try:\n",
    "    df = pd.read_csv('../data/processed/integrated_features_final.csv')\n",
    "    print(f\"üìä Dataset cargado: {df.shape}\")\n",
    "    \n",
    "    # Verificar si hay informaci√≥n temporal\n",
    "    temporal_columns = [col for col in df.columns if any(x in col.lower() for x in \n",
    "                       ['date', 'time', 'visit', 'month', 'year', 'baseline', 'followup'])]\n",
    "    \n",
    "    print(f\"üïê Columnas temporales detectadas: {len(temporal_columns)}\")\n",
    "    if temporal_columns:\n",
    "        print(\"üìã Columnas temporales disponibles:\")\n",
    "        for col in temporal_columns[:5]:\n",
    "            print(f\"   ‚Ä¢ {col}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: Archivo de features no encontrado\")\n",
    "    print(\"üí° Aseg√∫rate de ejecutar el notebook 03_feature_engineering_master.ipynb primero\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bbcd2e-b9b5-4b43-8739-55d7ae6315f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar analizador temporal\n",
    "temporal_analyzer = TemporalAnalyzer()\n",
    "\n",
    "# Simular datos temporales si no existen (com√∫n en datasets cross-sectional)\n",
    "if not temporal_columns:\n",
    "    print(\"‚ö†Ô∏è  No se detectaron columnas temporales expl√≠citas\")\n",
    "    print(\"üîÑ Generando estructura temporal simulada basada en patrones de datos\")\n",
    "    \n",
    "    # Crear estructura temporal simulada\n",
    "    np.random.seed(42)\n",
    "    n_patients = df['composite_risk_score'].notna().sum()\n",
    "    \n",
    "    # Simular m√∫ltiples visitas por paciente\n",
    "    visits_per_patient = np.random.poisson(3, n_patients) + 1  # 1-6 visitas\n",
    "    \n",
    "    temporal_data = []\n",
    "    patient_id = 0\n",
    "    \n",
    "    for i, n_visits in enumerate(visits_per_patient[:1000]):  # Limitar para demo\n",
    "        base_risk = df.loc[df['composite_risk_score'].notna()].iloc[i]['composite_risk_score']\n",
    "        \n",
    "        for visit in range(n_visits):\n",
    "            # Simular progresi√≥n temporal\n",
    "            months_elapsed = visit * 6  # Visitas cada 6 meses\n",
    "            risk_progression = base_risk + (visit * 0.05) + np.random.normal(0, 0.02)\n",
    "            risk_progression = np.clip(risk_progression, 0, 1)\n",
    "            \n",
    "            temporal_data.append({\n",
    "                'patient_id': patient_id,\n",
    "                'visit_number': visit,\n",
    "                'months_elapsed': months_elapsed,\n",
    "                'composite_risk_score': risk_progression,\n",
    "                'risk_velocity': 0.05 + np.random.normal(0, 0.01) if visit > 0 else 0\n",
    "            })\n",
    "        \n",
    "        patient_id += 1\n",
    "    \n",
    "    df_temporal = pd.DataFrame(temporal_data)\n",
    "    print(f\"üìä Datos temporales simulados: {df_temporal.shape}\")\n",
    "    print(f\"üë• Pacientes √∫nicos: {df_temporal['patient_id'].nunique()}\")\n",
    "    print(f\"üîÑ Visitas promedio por paciente: {df_temporal.groupby('patient_id').size().mean():.1f}\")\n",
    "\n",
    "else:\n",
    "    # Usar datos temporales reales\n",
    "    df_temporal = df.copy()\n",
    "    print(\"‚úÖ Usando datos temporales reales del dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f9750c-b281-41c3-9421-3fe1f16022f2",
   "metadata": {},
   "source": [
    "## An√°lisis exploratorio temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49808095-3a58-4f78-b098-dce556bd646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis exploratorio temporal\n",
    "with mlflow.start_run(run_name=\"temporal_exploration\"):\n",
    "    mlflow.set_tag(\"analysis_type\", \"exploratory\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Evoluci√≥n del riesgo promedio por visita\n",
    "    if 'visit_number' in df_temporal.columns:\n",
    "        risk_by_visit = df_temporal.groupby('visit_number')['composite_risk_score'].agg(['mean', 'std']).reset_index()\n",
    "        \n",
    "        axes[0,0].errorbar(risk_by_visit['visit_number'], risk_by_visit['mean'], \n",
    "                          yerr=risk_by_visit['std'], capsize=5, marker='o')\n",
    "        axes[0,0].set_title('Evoluci√≥n del Riesgo Promedio por Visita')\n",
    "        axes[0,0].set_xlabel('N√∫mero de Visita')\n",
    "        axes[0,0].set_ylabel('Score de Riesgo Promedio')\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Registrar m√©tricas\n",
    "        mlflow.log_metric(\"max_visits\", df_temporal['visit_number'].max())\n",
    "        mlflow.log_metric(\"avg_risk_increase_per_visit\", \n",
    "                         (risk_by_visit['mean'].iloc[-1] - risk_by_visit['mean'].iloc[0]) / len(risk_by_visit))\n",
    "    \n",
    "    # 2. Distribuci√≥n de velocidad de cambio\n",
    "    if 'risk_velocity' in df_temporal.columns:\n",
    "        velocities = df_temporal[df_temporal['risk_velocity'] != 0]['risk_velocity']\n",
    "        axes[0,1].hist(velocities, bins=30, alpha=0.7, color='lightcoral')\n",
    "        axes[0,1].set_title('Distribuci√≥n de Velocidad de Cambio del Riesgo')\n",
    "        axes[0,1].set_xlabel('Velocidad de Cambio')\n",
    "        axes[0,1].set_ylabel('Frecuencia')\n",
    "        \n",
    "        mlflow.log_metric(\"mean_risk_velocity\", velocities.mean())\n",
    "        mlflow.log_metric(\"std_risk_velocity\", velocities.std())\n",
    "    \n",
    "    # 3. Trayectorias individuales (muestra)\n",
    "    sample_patients = df_temporal['patient_id'].unique()[:10]\n",
    "    for patient in sample_patients:\n",
    "        patient_data = df_temporal[df_temporal['patient_id'] == patient]\n",
    "        if len(patient_data) > 1:\n",
    "            axes[1,0].plot(patient_data['months_elapsed'], patient_data['composite_risk_score'], \n",
    "                          alpha=0.6, marker='o', markersize=3)\n",
    "    \n",
    "    axes[1,0].set_title('Trayectorias Individuales de Riesgo (Muestra)')\n",
    "    axes[1,0].set_xlabel('Meses Transcurridos')\n",
    "    axes[1,0].set_ylabel('Score de Riesgo')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Correlaci√≥n temporal\n",
    "    if len(df_temporal) > 100:\n",
    "        # Calcular autocorrelaci√≥n por paciente\n",
    "        autocorr_data = []\n",
    "        for patient in df_temporal['patient_id'].unique()[:50]:\n",
    "            patient_data = df_temporal[df_temporal['patient_id'] == patient].sort_values('months_elapsed')\n",
    "            if len(patient_data) >= 3:\n",
    "                risk_series = patient_data['composite_risk_score'].values\n",
    "                autocorr = np.corrcoef(risk_series[:-1], risk_series[1:])[0,1]\n",
    "                if not np.isnan(autocorr):\n",
    "                    autocorr_data.append(autocorr)\n",
    "        \n",
    "        if autocorr_data:\n",
    "            axes[1,1].hist(autocorr_data, bins=20, alpha=0.7, color='lightgreen')\n",
    "            axes[1,1].set_title('Distribuci√≥n de Autocorrelaci√≥n')\n",
    "            axes[1,1].set_xlabel('Correlaci√≥n lag-1')\n",
    "            axes[1,1].set_ylabel('Frecuencia')\n",
    "            \n",
    "            mlflow.log_metric(\"mean_autocorrelation\", np.mean(autocorr_data))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìä An√°lisis exploratorio temporal completado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25555dd0-5e42-4370-9143-8b36c929e1fa",
   "metadata": {},
   "source": [
    "## An√°lisis de tendencias con TemporalAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e0052-585a-40ad-afdd-39bded70534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de tendencias con TemporalAnalyzer\n",
    "with mlflow.start_run(run_name=\"trend_analysis\"):\n",
    "    mlflow.set_tag(\"analysis_type\", \"trend_detection\")\n",
    "    \n",
    "    # Detectar tendencias por paciente\n",
    "    trend_results = temporal_analyzer.detect_trends(\n",
    "        df_temporal, \n",
    "        patient_col='patient_id',\n",
    "        time_col='months_elapsed',\n",
    "        value_col='composite_risk_score'\n",
    "    )\n",
    "    \n",
    "    print(\"üìà AN√ÅLISIS DE TENDENCIAS\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Pacientes analizados: {len(trend_results)}\")\n",
    "    \n",
    "    # Clasificar tendencias\n",
    "    increasing_trends = sum(1 for r in trend_results if r['slope'] > 0.01)\n",
    "    stable_trends = sum(1 for r in trend_results if abs(r['slope']) <= 0.01)\n",
    "    decreasing_trends = sum(1 for r in trend_results if r['slope'] < -0.01)\n",
    "    \n",
    "    print(f\"Tendencias crecientes: {increasing_trends} ({increasing_trends/len(trend_results)*100:.1f}%)\")\n",
    "    print(f\"Tendencias estables: {stable_trends} ({stable_trends/len(trend_results)*100:.1f}%)\")\n",
    "    print(f\"Tendencias decrecientes: {decreasing_trends} ({decreasing_trends/len(trend_results)*100:.1f}%)\")\n",
    "    \n",
    "    # Registrar m√©tricas\n",
    "    mlflow.log_metric(\"patients_with_increasing_risk\", increasing_trends)\n",
    "    mlflow.log_metric(\"patients_with_stable_risk\", stable_trends)\n",
    "    mlflow.log_metric(\"patients_with_decreasing_risk\", decreasing_trends)\n",
    "    mlflow.log_metric(\"median_slope\", np.median([r['slope'] for r in trend_results]))\n",
    "    \n",
    "    # Visualizar distribuci√≥n de pendientes\n",
    "    slopes = [r['slope'] for r in trend_results]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(slopes, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.axvline(np.median(slopes), color='red', linestyle='--', label=f'Mediana: {np.median(slopes):.4f}')\n",
    "    plt.title('Distribuci√≥n de Pendientes de Tendencia')\n",
    "    plt.xlabel('Pendiente (cambio en riesgo por mes)')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ab97f5-ea05-4859-afdc-125699a9fd8b",
   "metadata": {},
   "source": [
    "## Modelos predictivos temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159acd2-c950-40d9-a9e6-cc86eb253920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos predictivos temporales\n",
    "predictor = TimeSeriesPredictor()\n",
    "\n",
    "with mlflow.start_run(run_name=\"temporal_prediction\"):\n",
    "    mlflow.set_tag(\"model_type\", \"time_series_prediction\")\n",
    "    \n",
    "    # Seleccionar pacientes con suficientes datos temporales\n",
    "    patients_with_data = df_temporal.groupby('patient_id').size()\n",
    "    eligible_patients = patients_with_data[patients_with_data >= 3].index\n",
    "    \n",
    "    print(f\"üë• Pacientes elegibles para predicci√≥n: {len(eligible_patients)}\")\n",
    "    \n",
    "    # Entrenar modelos predictivos\n",
    "    prediction_results = []\n",
    "    \n",
    "    for patient in eligible_patients[:100]:  # Limitar para demo\n",
    "        patient_data = df_temporal[df_temporal['patient_id'] == patient].sort_values('months_elapsed')\n",
    "        \n",
    "        if len(patient_data) >= 4:  # M√≠nimo 4 puntos\n",
    "            # Dividir en train/test temporal\n",
    "            split_point = len(patient_data) - 1\n",
    "            train_data = patient_data.iloc[:split_point]\n",
    "            test_data = patient_data.iloc[split_point:]\n",
    "            \n",
    "            # Predicci√≥n simple (tendencia linear)\n",
    "            prediction = predictor.predict_next_value(\n",
    "                train_data['months_elapsed'].values,\n",
    "                train_data['composite_risk_score'].values,\n",
    "                test_data['months_elapsed'].iloc[0]\n",
    "            )\n",
    "            \n",
    "            actual = test_data['composite_risk_score'].iloc[0]\n",
    "            error = abs(prediction - actual)\n",
    "            \n",
    "            prediction_results.append({\n",
    "                'patient_id': patient,\n",
    "                'predicted': prediction,\n",
    "                'actual': actual,\n",
    "                'error': error,\n",
    "                'relative_error': error / actual if actual > 0 else 0\n",
    "            })\n",
    "    \n",
    "    # An√°lisis de resultados de predicci√≥n\n",
    "    if prediction_results:\n",
    "        pred_df = pd.DataFrame(prediction_results)\n",
    "        \n",
    "        mae = pred_df['error'].mean()\n",
    "        rmse = np.sqrt((pred_df['error'] ** 2).mean())\n",
    "        mape = pred_df['relative_error'].mean() * 100\n",
    "        \n",
    "        print(f\"üìä RESULTADOS DE PREDICCI√ìN TEMPORAL\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAPE: {mape:.2f}%\")\n",
    "        \n",
    "        # Registrar m√©tricas\n",
    "        mlflow.log_metric(\"temporal_mae\", mae)\n",
    "        mlflow.log_metric(\"temporal_rmse\", rmse)\n",
    "        mlflow.log_metric(\"temporal_mape\", mape)\n",
    "        mlflow.log_metric(\"predictions_made\", len(prediction_results))\n",
    "        \n",
    "        # Visualizar predicciones vs actual\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(pred_df['actual'], pred_df['predicted'], alpha=0.6)\n",
    "        plt.plot([pred_df['actual'].min(), pred_df['actual'].max()], \n",
    "                [pred_df['actual'].min(), pred_df['actual'].max()], \n",
    "                'r--', label='Predicci√≥n perfecta')\n",
    "        plt.xlabel('Valor Real')\n",
    "        plt.ylabel('Valor Predicho')\n",
    "        plt.title('Predicciones Temporales vs Valores Reales')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3069a5-c5ff-4e2f-b51e-f1a5e88f092a",
   "metadata": {},
   "source": [
    "## An√°lisis de patrones de actividad temporal (si disponible) y Detecci√≥n de cambios significativos (change points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a765be10-63f1-414d-8f63-e9579a04004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de patrones de actividad temporal (si disponible)\n",
    "activity_columns = [col for col in df.columns if 'sleep' in col.lower() or 'activity' in col.lower()]\n",
    "\n",
    "if activity_columns:\n",
    "    with mlflow.start_run(run_name=\"activity_temporal_patterns\"):\n",
    "        mlflow.set_tag(\"analysis_type\", \"activity_patterns\")\n",
    "        \n",
    "        print(\"üèÉ AN√ÅLISIS DE PATRONES TEMPORALES DE ACTIVIDAD\")\n",
    "        print(\"=\" * 55)\n",
    "        \n",
    "        # Seleccionar features clave de actividad\n",
    "        key_activity_features = activity_columns[:5]  # Top 5 features\n",
    "        \n",
    "        # Simular variabilidad temporal en actividad\n",
    "        activity_temporal = []\n",
    "        \n",
    "        for patient in eligible_patients[:50]:  # Muestra reducida\n",
    "            patient_base = df[df.index % len(eligible_patients) == patient % len(eligible_patients)]\n",
    "            \n",
    "            for visit in range(3):  # 3 visitas simuladas\n",
    "                activity_row = {\n",
    "                    'patient_id': patient,\n",
    "                    'visit': visit,\n",
    "                    'months_elapsed': visit * 6\n",
    "                }\n",
    "                \n",
    "                # Simular cambios temporales en actividad\n",
    "                for feature in key_activity_features:\n",
    "                    if feature in patient_base.columns:\n",
    "                        base_value = patient_base[feature].iloc[0] if not patient_base[feature].isna().iloc[0] else 0\n",
    "                        # A√±adir variabilidad temporal y tendencia\n",
    "                        temporal_change = base_value + (visit * 0.1 * np.random.normal(0, 0.5))\n",
    "                        activity_row[feature] = temporal_change\n",
    "                \n",
    "                activity_temporal.append(activity_row)\n",
    "        \n",
    "        activity_df = pd.DataFrame(activity_temporal)\n",
    "        \n",
    "        # An√°lizar cambios temporales en actividad\n",
    "        for feature in key_activity_features:\n",
    "            if feature in activity_df.columns:\n",
    "                activity_trends = activity_df.groupby('visit')[feature].mean()\n",
    "                trend_slope = np.polyfit(activity_trends.index, activity_trends.values, 1)[0]\n",
    "                \n",
    "                mlflow.log_metric(f\"activity_{feature}_trend_slope\", trend_slope)\n",
    "                print(f\"üìä {feature}: tendencia = {trend_slope:.4f}\")\n",
    "        \n",
    "        # Visualizar patrones temporales de actividad\n",
    "        if len(key_activity_features) >= 2:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "            \n",
    "            # Evoluci√≥n temporal del primer feature\n",
    "            feature1 = key_activity_features[0]\n",
    "            activity_evolution = activity_df.groupby('visit')[feature1].agg(['mean', 'std']).reset_index()\n",
    "            \n",
    "            axes[0].errorbar(activity_evolution['visit'], activity_evolution['mean'], \n",
    "                           yerr=activity_evolution['std'], capsize=5, marker='o')\n",
    "            axes[0].set_title(f'Evoluci√≥n Temporal: {feature1}')\n",
    "            axes[0].set_xlabel('Visita')\n",
    "            axes[0].set_ylabel('Valor Promedio')\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Correlaci√≥n entre features de actividad a lo largo del tiempo\n",
    "            if len(key_activity_features) >= 2:\n",
    "                feature2 = key_activity_features[1]\n",
    "                for visit in activity_df['visit'].unique():\n",
    "                    visit_data = activity_df[activity_df['visit'] == visit]\n",
    "                    if len(visit_data) > 5:\n",
    "                        axes[1].scatter(visit_data[feature1], visit_data[feature2], \n",
    "                                      alpha=0.6, label=f'Visita {visit}')\n",
    "                \n",
    "                axes[1].set_xlabel(feature1)\n",
    "                axes[1].set_ylabel(feature2)\n",
    "                axes[1].set_title('Correlaci√≥n Temporal entre Features de Actividad')\n",
    "                axes[1].legend()\n",
    "                axes[1].grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1a0e5-e36f-49b9-959c-76d275a66abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecci√≥n de cambios significativos (change points)\n",
    "with mlflow.start_run(run_name=\"change_point_detection\"):\n",
    "    mlflow.set_tag(\"analysis_type\", \"change_point_detection\")\n",
    "    \n",
    "    # Detectar cambios significativos en las trayectorias\n",
    "    changepoints_detected = []\n",
    "    \n",
    "    for patient in eligible_patients[:50]:\n",
    "        patient_data = df_temporal[df_temporal['patient_id'] == patient].sort_values('months_elapsed')\n",
    "        \n",
    "        if len(patient_data) >= 5:\n",
    "            risk_values = patient_data['composite_risk_score'].values\n",
    "            \n",
    "            # Detecci√≥n simple de cambios (diferencias significativas)\n",
    "            changes = temporal_analyzer.detect_changepoints(risk_values)\n",
    "            \n",
    "            if changes:\n",
    "                changepoints_detected.append({\n",
    "                    'patient_id': patient,\n",
    "                    'n_changepoints': len(changes),\n",
    "                    'changepoint_positions': changes\n",
    "                })\n",
    "    \n",
    "    print(f\"üîç DETECCI√ìN DE PUNTOS DE CAMBIO\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Pacientes con cambios detectados: {len(changepoints_detected)}\")\n",
    "    \n",
    "    if changepoints_detected:\n",
    "        n_changes = [cp['n_changepoints'] for cp in changepoints_detected]\n",
    "        print(f\"Promedio de cambios por paciente: {np.mean(n_changes):.2f}\")\n",
    "        print(f\"M√°ximo de cambios detectados: {max(n_changes)}\")\n",
    "        \n",
    "        mlflow.log_metric(\"patients_with_changepoints\", len(changepoints_detected))\n",
    "        mlflow.log_metric(\"avg_changepoints_per_patient\", np.mean(n_changes))\n",
    "        mlflow.log_metric(\"max_changepoints\", max(n_changes))\n",
    "        \n",
    "        # Visualizar distribuci√≥n de cambios\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(n_changes, bins=range(max(n_changes)+2), alpha=0.7, color='orange', edgecolor='black')\n",
    "        plt.title('Distribuci√≥n de Puntos de Cambio por Paciente')\n",
    "        plt.xlabel('N√∫mero de Puntos de Cambio')\n",
    "        plt.ylabel('Frecuencia')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a351e97-317f-4f14-98df-b41ef4ce9391",
   "metadata": {},
   "source": [
    "## Resumen del an√°lisis temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c09e9-d536-45e1-9d8b-a5e96d68c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen del an√°lisis temporal\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä RESUMEN DEL AN√ÅLISIS TEMPORAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "temporal_summary = {\n",
    "    'Total_Observaciones_Temporales': len(df_temporal),\n",
    "    'Pacientes_√önicos': df_temporal['patient_id'].nunique(),\n",
    "    'Visitas_Promedio_por_Paciente': df_temporal.groupby('patient_id').size().mean(),\n",
    "    'Rango_Temporal_Meses': df_temporal['months_elapsed'].max() - df_temporal['months_elapsed'].min(),\n",
    "}\n",
    "\n",
    "if 'trend_results' in locals():\n",
    "    temporal_summary['Pacientes_con_Tendencia_Creciente'] = increasing_trends\n",
    "    temporal_summary['Pacientes_con_Tendencia_Estable'] = stable_trends\n",
    "\n",
    "if 'prediction_results' in locals():\n",
    "    temporal_summary['Predicciones_Realizadas'] = len(prediction_results)\n",
    "    temporal_summary['Error_Promedio_Predicci√≥n'] = f\"{mae:.4f}\"\n",
    "\n",
    "if changepoints_detected:\n",
    "    temporal_summary['Pacientes_con_Cambios_Detectados'] = len(changepoints_detected)\n",
    "\n",
    "for key, value in temporal_summary.items():\n",
    "    print(f\"üéØ {key}: {value}\")\n",
    "\n",
    "# Guardar resultados temporales\n",
    "if 'df_temporal' in locals():\n",
    "    df_temporal.to_csv('../data/processed/temporal_analysis_results.csv', index=False)\n",
    "    print(\"\\nüìÅ Resultados temporales guardados en: ../data/processed/temporal_analysis_results.csv\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lisis temporal completado exitosamente\")\n",
    "print(\"üìä Modelos temporales desarrollados y evaluados\")\n",
    "print(\"üîÑ Listo para integraci√≥n con otros modelos en la fase de ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcee44e4-f73c-46ea-a437-af19df4fb0c7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc856807-1e1f-4c97-bfb7-446f1b402050",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b82f4-daed-4ee9-ba31-327f05015b99",
   "metadata": {},
   "source": [
    "**Abraham Tartalos**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Alzheimer)",
   "language": "python",
   "name": "alzheimer-env-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
